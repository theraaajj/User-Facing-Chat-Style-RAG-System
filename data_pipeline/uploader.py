
# This module:
# Reads the processed JSON files generated by the processor
# Connects to the MySQL database
# Inserts each record into the relevant table



## pipeline/uploader.py
import os
import json
import asyncio
import aiomysql
from datetime import datetime, timezone
from dotenv import load_dotenv
import aiofiles

load_dotenv()

DB_CONFIG = {
    'host': os.getenv('DB_HOST'),
    'port': int(os.getenv('DB_PORT')),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),
    'db': os.getenv('DB_NAME')
}

PROCESSED_DATA_DIR = "data_pipeline/processed_data"

async def insert_data(pool, record):
    async with pool.acquire() as conn:
        async with conn.cursor() as cur:
            # Use alias for VALUES() to fix deprecation warning in MySQL 8.0.20+
            sql = """
                INSERT INTO federal_register_documents
                (document_id, title, summary, publication_date, topics, raw_json, last_updated)
                VALUES (%s, %s, %s, %s, %s, %s, %s) AS new_vals
                ON DUPLICATE KEY UPDATE
                    title = new_vals.title,
                    summary = new_vals.summary,
                    publication_date = new_vals.publication_date,
                    topics = new_vals.topics,
                    raw_json = new_vals.raw_json,
                    last_updated = new_vals.last_updated
            """
            try:
                # Execute with record values
                await cur.execute(sql, (
                    record['document_id'],
                    record['title'],
                    record['summary'],
                    record['publication_date'],
                    record['topics'],
                    record['raw_json'],
                    record['last_updated']
                ))
                await conn.commit()  # Commit after each insert/update
            except Exception as e:
                print(f"Error inserting document_id={record['document_id']}: {e}")

async def process_and_upload(pool, file_path):
    print(f"Processing file: {file_path}")

    async with aiofiles.open(file_path, mode='r') as f:
        content = await f.read()
        data = json.loads(content)

    for doc in data:
        document_id = doc.get('document_id', '').strip()
        if not document_id:
            print(f"‚ö†Ô∏è Skipping record with empty 'document_id'. File: {file_path}")
            continue

        record = {
            'document_id': document_id,
            'title': doc.get('title', ''),
            'summary': doc.get('summary', ''),
            'publication_date': doc.get('publication_date', None),
            'topics': doc.get('topics', ''),
            'raw_json': doc.get('raw_json', '{}'),
            'last_updated': datetime.now(timezone.utc)
        }

        await insert_data(pool, record)

async def main():
    pool = await aiomysql.create_pool(
        autocommit=True,
        **DB_CONFIG)
    async with pool.acquire() as conn:
        async with conn.cursor() as cur:
            await cur.execute("SELECT DATABASE()")
            db = await cur.fetchone()
            print(f"‚úÖ Connected to database: {db[0]}")

            await cur.execute("SELECT current_user();")
            user = await cur.fetchone()
            print(f"üë§ Connected as user: {user[0]}")

            await cur.execute("SHOW VARIABLES LIKE 'hostname';")
            host = await cur.fetchone()
            print(f"üåê Connected to host: {host[1]}")

    json_files = [
        os.path.join(PROCESSED_DATA_DIR, f)
        for f in os.listdir(PROCESSED_DATA_DIR)
        if f.endswith('.json')
    ]

    for file_path in json_files:
        await process_and_upload(pool, file_path)

    pool.close()
    await pool.wait_closed()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"Error: {e}")


## This script uploads all processed JSON files from the specified directory
## to the MySQL database table `federal_register_documents`.



# import asyncio
# import aiomysql
# import os
# from datetime import datetime, timezone
# from dotenv import load_dotenv

# load_dotenv()

# DB_CONFIG = {
#     'host': os.getenv('DB_HOST'),
#     'port': int(os.getenv('DB_PORT')),
#     'user': os.getenv('DB_USER'),
#     'password': os.getenv('DB_PASSWORD'),
#     'db': os.getenv('DB_NAME')
# }

# async def test_insert():
#     try:
#         pool = await aiomysql.create_pool(autocommit=True, **DB_CONFIG)
#         async with pool.acquire() as conn:
#             async with conn.cursor() as cur:
#                 await cur.execute("SELECT DATABASE();")
#                 current_db = await cur.fetchone()
#                 print("Connected to database:", current_db[0])

#                 sql = """
#                     INSERT INTO federal_register_documents
#                     (document_id, title, summary, publication_date, topics, raw_json, last_updated)
#                     VALUES (%s, %s, %s, %s, %s, %s, %s)
#                 """
#                 dummy_data = (
#                     "dummy-doc-002",
#                     "Dummy Title 2",
#                     "This is another dummy summary.",
#                     datetime.now(timezone.utc).strftime('%Y-%m-%d'),
#                     "dummy topic",
#                     "{}",
#                     datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
#                 )
#                 await cur.execute(sql, dummy_data)
#                 # no need for commit with autocommit=True

#                 print("‚úÖ Dummy row inserted successfully!")

#                 # Check rows count
#                 await cur.execute("SELECT COUNT(*) FROM federal_register_documents;")
#                 row_count = await cur.fetchone()
#                 print("Total rows in federal_register_documents:", row_count[0])

#                 # Fetch recent rows
#                 await cur.execute("SELECT document_id, title FROM federal_register_documents ORDER BY last_updated DESC LIMIT 5;")
#                 recent_rows = await cur.fetchall()
#                 print("Recent rows:")
#                 for row in recent_rows:
#                     print(row)

#         pool.close()
#         await pool.wait_closed()
#     except Exception as e:
#         print(f"‚ùå Error during dummy insert: {e}")

# if __name__ == "__main__":
#     asyncio.run(test_insert())
